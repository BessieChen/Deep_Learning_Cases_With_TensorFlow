{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image #图像处理库\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/bessie/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG中自带常量，VGG有将图片进行预处理，其中一个步骤是normalization:\n",
    "#减去image_net的RGB通道的各个均值\n",
    "VGG_MEAN = [103.939, 116.779, 123.68] #在vggnet的code中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGNet:\n",
    "    \"\"\"Builds VGG-16 net structure,\n",
    "        load parameters from pre-trained models.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dict):\n",
    "        self.data_dict = data_dict\n",
    "        \n",
    "    def get_conv_filter(self, name): #抽取卷积参数\n",
    "        \"\"\"eg. conv1_1 = data_dict['conv1_1']\"\"\"\n",
    "        #tf.constant() #因为模型是预处理好的，所以我们不会改变参数，所以定义为常量。\n",
    "        #另一个方法：可以设置成trainable = False\n",
    "        return tf.constant(self.data_dict[name][0], name = 'conv') #这里应该是w,b中的w\n",
    "    \n",
    "    def get_fc_weight(self, name):\n",
    "        return tf.constant(self.data_dict[name][0], name = 'fc') #这里应该是w,b中的w\n",
    "    \n",
    "    def get_bias(self, name):\n",
    "        return tf.constant(self.data_dict[name][1], name = 'bias') #这里应该是w,b中的b\n",
    "    \n",
    "    #创建卷积层，池化层，全连接层\n",
    "    def conv_layer(self, x, name):\n",
    "        \"\"\"Builds convolution layer.\"\"\"\n",
    "        with tf.name_scope(name):\n",
    "            #加上name_scope是命名规范：\n",
    "            #1. 防止命名冲突\n",
    "            #2. tensorboard打印名字更加清晰规范\n",
    "            conv_w = self.get_conv_filter(name)\n",
    "            conv_b = self.get_bias(name)\n",
    "            \n",
    "            #现在不再使用tf.layers.conv2d(),因为我们已经有了pre-trained的参数\n",
    "            #现在使用更基础的api: tf.nn.conv2d()\n",
    "            h = tf.nn.conv2d(x, conv_w, [1,1,1,1], padding = 'same') #x是input，[1,1,1,1]是strides步长，因为这里x是四维，所以我们输入四个数\n",
    "            h = tf.nn.bias_add(h, conv_b)\n",
    "            \n",
    "            #激活函数\n",
    "            h = tf.nn.relu(h)\n",
    "            return h\n",
    "        \n",
    "    #也是使用tf.nn.max_pooling()而不是tf.layers.max_pooling2d\n",
    "    def pooling_layer(self, x, name):\n",
    "        \"\"\"Builds pooling layer.\"\"\"\n",
    "        return tf.nn.max_pooling(x,\n",
    "                                 ksize = [1,2,2,1], #因为是按照长和宽来池化，所以是中间两个维度是2，其余维度是1\n",
    "                                 strides = [1,2,2,1], \n",
    "                                 padding = 'same', \n",
    "                                 name = name) \n",
    "    \n",
    "    \n",
    "    def fc_layer(self, x, name, activation = tf.nn.relu):\n",
    "        \"\"\"Builds fully-connected layer.\"\"\"\n",
    "        with tf.name_scope(name):\n",
    "            fc_w = self.get_fc_weight(name)\n",
    "            fc_b = self.get_bias(name)\n",
    "            h = tf.matmul(x, fc_w) #让输入x与w进行操作\n",
    "            h = tf.nn.bias_add(h, fc_b)\n",
    "            if activation == None:\n",
    "                return h\n",
    "            else:\n",
    "                return activation(h)\n",
    "            \n",
    "    \n",
    "    #创建展平功能，展平后输入给全连接层：做的是reshape操作，我们需要知道reshape之后的size有多大\n",
    "    #展平之后，需要的长宽厚的乘积\n",
    "    def flatten_layer(self, x, name):\n",
    "        \"\"\"Builds flatten layer.\"\"\"\n",
    "        with tf.name_scope(name):\n",
    "            #[batch_size, img_width, img_height, channel]\n",
    "            x_shape = x.get_shape().as_list()\n",
    "            dim = 1\n",
    "            for d in x_shape[1:]:\n",
    "                dim *= d\n",
    "            x = tf.reshape(x, [-1, dim]) #这里的-1，是reshape推断出来的，也是我们的batch_size, 你也可以写成[x_shape[0], dim]\n",
    "            return x\n",
    "       \n",
    "    #建立vgg\n",
    "    #我们现在就要做图像的风格转换，需要的图片只有一个，所以第一个维度是1\n",
    "    #vggnet的设置中，图像大小是224*224\n",
    "    def build(self, x_rgb):\n",
    "        \"\"\"BUild VGG16 network structure.\n",
    "        Args:\n",
    "        - x_rgb: eg. [1, 224, 224, 3]\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        print(\"Building model...\")\n",
    "        \n",
    "        #每个通道减去均值VGG_MEAN，先拆分通道\n",
    "        #复习：tf.split() 之前用于：深度可分离卷积，数据增强\n",
    "        r, g, b = tf.split(x_rgb, [1,1,1], axis = 3) #切分成三通道：[1,1,1]\n",
    "        \n",
    "        #去除均值后，需要合并。这里注意vggnet输入的通道顺序是BGR\n",
    "        #意味着之前写的VGG_MEAN的三个数分别是 BGR 的均值\n",
    "        x_bgr = tf.concat([b - VGG_MEAN[0], \n",
    "                           g - VGG_MEAN[1],\n",
    "                           r - VGG_MEAN[2]],\n",
    "                          axis = 3) #在第四个维度，channel上合并\n",
    "        \n",
    "        #预处理之后，判断一下我们的维度是 224*224*3\n",
    "        assert x_bgr.get_shape().as_list()[1:] == [224,224,3]\n",
    "        \n",
    "        #构建前两个卷积层：\n",
    "        #vgg16：\n",
    "        #第一个结构(stage)：两个卷积层 -> 一个池化层\n",
    "        #第二个结构：两个卷积层 -> 一个池化层\n",
    "        #第3个结构：3个卷积层 -> 一个池化层\n",
    "        #第4个结构：3个卷积层 -> 一个池化层\n",
    "        #第5个结构：3个卷积层 -> 一个池化层\n",
    "        #第6个结构：3个全连接层\n",
    "        #2*2 + 3*3 + 3 = 4 + 9 + 3 = 16, 也就是vgg16 \n",
    "        \n",
    "        ##注意：self.conv_layer(xx,yy)第二个参数的名字必须是data_dict.keys()中的\n",
    "        #dict_keys(['conv5_1', 'fc6', 'conv5_3', 'conv5_2', 'fc8', 'fc7', 'conv4_1', 'conv4_2', 'conv4_3', 'conv3_3', 'conv3_2', 'conv3_1', 'conv1_1', 'conv1_2', 'conv2_2', 'conv2_1'])\n",
    "        #我们将每一个层，设置成了成员变量, eg. self.conv1_1, 可能会用其中的某一层计算风格损失或者内容损失，设置成成员变量我们以后可以方便使用\n",
    "        self.conv1_1 = self.conv_layer(x_bgr, 'conv1_1')\n",
    "        self.conv1_2 = self.conv_layer(self.conv1_1, 'conv1_2')\n",
    "        self.pool1 = self.pooling_layer(self.conv1_2, 'pool1') #pool1因为不是data_dict里面预处理好的，所以我们可以随意命名, 例如pool1。并且可以不用将它设置成成员函数，只不过这里为了统一起见\n",
    "        \n",
    "        self.conv2_1 = self.conv_layer(self.pool1, 'conv2_1')\n",
    "        self.conv2_2 = self.conv_layer(self.conv2_1, 'conv2_2')\n",
    "        self.pool2 = self.pooling_layer(self.conv2_2, 'pool2')\n",
    "        \n",
    "        self.conv3_1 = self.conv_layer(self.pool2, 'conv3_1')\n",
    "        self.conv3_2 = self.conv_layer(self.conv3_1, 'conv3_2')\n",
    "        self.conv3_3 = self.conv_layer(self.conv3_2, 'conv3_3')\n",
    "        self.pool3 = self.pooling_layer(self.conv3_3, 'pool3')\n",
    "        \n",
    "        self.conv4_1 = self.conv_layer(self.pool3, 'conv4_1')\n",
    "        self.conv4_2 = self.conv_layer(self.conv4_1, 'conv4_2')\n",
    "        self.conv4_3 = self.conv_layer(self.conv4_2, 'conv4_3')\n",
    "        self.pool4 = self.pooling_layer(self.conv4_3, 'pool4')\n",
    "        \n",
    "        self.conv5_1 = self.conv_layer(self.pool4, 'conv5_1')\n",
    "        self.conv5_2 = self.conv_layer(self.conv5_1, 'conv5_2')\n",
    "        self.conv5_3 = self.conv_layer(self.conv5_2, 'conv5_3')\n",
    "        self.pool5 = self.pooling_layer(self.conv5_3, 'pool5')\n",
    "        \n",
    "        #展开 -> 全连接\n",
    "        self.flatten5 = self.flatten_layer(self.pool5, 'flatten')\n",
    "        self.fc6 = self.fc_layer(self.flatten, 'fc6')\n",
    "        self.fc7 = self.fc_layer(self.fc6, 'fc7')\n",
    "        \n",
    "        #最后的fc8输出1k个值，给softmax()去计算概率分布\n",
    "        #所以fc8不需要activation\n",
    "        self.fc8 = self.fc_layer(self.fc7, 'fc8', activation = None)\n",
    "        \n",
    "        #计算softmax\n",
    "        self.prob = tf.nn.softmax(self.fc8, name = 'prob')\n",
    "        \n",
    "        print(\"Building model finished: %4ds\" % (time.time() - start_time))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Attr 'padding' of 'Conv2D' Op passed string 'same' not in: \"SAME\", \"VALID\", \"EXPLICIT\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6e72d23ab685>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvgg16_for_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGGNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mvgg16_for_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-f1b47fdf79ce>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, x_rgb)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m#dict_keys(['conv5_1', 'fc6', 'conv5_3', 'conv5_2', 'fc8', 'fc7', 'conv4_1', 'conv4_2', 'conv4_3', 'conv3_3', 'conv3_2', 'conv3_1', 'conv1_1', 'conv1_2', 'conv2_2', 'conv2_1'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m#我们将每一个层，设置成了成员变量, eg. self.conv1_1, 可能会用其中的某一层计算风格损失或者内容损失，设置成成员变量我们以后可以方便使用\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_bgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'conv1_1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'conv1_2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooling_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pool1'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#pool1因为不是data_dict里面预处理好的，所以我们可以随意命名, 例如pool1。并且可以不用将它设置成成员函数，只不过这里为了统一起见\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-f1b47fdf79ce>\u001b[0m in \u001b[0;36mconv_layer\u001b[0;34m(self, x, name)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m#现在不再使用tf.layers.conv2d(),因为我们已经有了pre-trained的参数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m#现在使用更基础的api: tf.nn.conv2d()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#x是input，[1,1,1,1]是strides步长，因为这里x是四维，所以我们输入四个数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)\u001b[0m\n\u001b[1;32m   2009\u001b[0m                            \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m                            \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m                            name=name)\n\u001b[0m\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    967\u001b[0m                   \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m                   \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m                   data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[1;32m    970\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    659\u001b[0m                 (key, op_type_name, compat.as_text(attr_value.s),\n\u001b[1;32m    660\u001b[0m                  '\", \"'.join(map(compat.as_text,\n\u001b[0;32m--> 661\u001b[0;31m                                  attr_def.allowed_values.list.s))))\n\u001b[0m\u001b[1;32m    662\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mattr_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"list(string)\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0mattr_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_MakeStr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Attr 'padding' of 'Conv2D' Op passed string 'same' not in: \"SAME\", \"VALID\", \"EXPLICIT\"."
     ]
    }
   ],
   "source": [
    "#加载vgg16\n",
    "vgg16_npy_path = '../../../other_datasets/vgg16.npy'\n",
    "data_dict = np.load(vgg16_npy_path, encoding = 'latin1').item() #加item()是为了创建成字典\n",
    "\n",
    "vgg16_for_result = VGGNet(data_dict)\n",
    "content = tf.placeholder(tf.float32, shape = [1,224,224,3])\n",
    "vgg16_for_result.build(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
